kafka:
  events:
    # topic-maps (acapy topic regex to kafka topic template): A mapping from regex
    #     matching ACA-Py event topics to kafka topics. The Kafka topic can be templated;
    #     the plugin will insert the following values:
    #
    #     $wallet_id: the id of the subwallet emitting the event or "base" if
    #         the base wallet
    #     $state: the state associated with the event (not all events have state)
    #     $topic: the acapy event topic
    #     $category: the acapy topic "category" or the portion following
    #         "acapy::record::" and "acapy::webhook::" in acapy events.
    topic-maps:
      "^acapy::webhook::(.*)$": "webhook-$wallet_id"
      "^acapy::record::connections::.*": "connections-$wallet_id"
      "^acapy::record::issue_credential::.*": "issue-credential-v1-$wallet_id"
      "^acapy::record::issue_credential_v2_0::.*": "issue-credential-v2-$wallet_id"
      "^acapy::record::present_proof::.*": "present-proof-v1-$wallet_id"
      "^acapy::record::present_proof_v2_0::.*": "present-proof-v2-$wallet_id"
      # TODO There are likely more topics you are interested in

    producer:
      # Minimum required config
      # bootstrap-servers: 'host[:port]' string (or list of 'host[:port]'
      #     strings) that the producer should contact to bootstrap initial
      #     cluster metadata. This does not have to be the full node list.
      #     It just needs to have at least one broker that will respond to a
      #     Metadata API Request. Default port is 9092. If no servers are
      #     specified, will default to localhost:9092.
      bootstrap-servers: kafka

      # Extras
      # client-id (str): a name for this client. This string is passed in
      #     each request to servers and can be used to identify specific
      #     server-side log entries that correspond to this client.
      #     Default: 'aiokafka-producer-#' (appended with a unique number
      #     per instance)
      client-id: events

      # acks (0, 1, 'all'): The number of acknowledgments the producer requires
      #     the leader to have received before considering a request complete.
      #     This controls the durability of records that are sent. The
      #     following settings are common:

      #     0: Producer will not wait for any acknowledgment from the server
      #         at all. The message will immediately be added to the socket
      #         buffer and considered sent. No guarantee can be made that the
      #         server has received the record in this case, and the retries
      #         configuration will not take effect (as the client won't
      #         generally know of any failures). The offset given back for each
      #         record will always be set to -1.
      #     1: The broker leader will write the record to its local log but
      #         will respond without awaiting full acknowledgement from all
      #         followers. In this case should the leader fail immediately
      #         after acknowledging the record but before the followers have
      #         replicated it then the record will be lost.
      #     all: The broker leader will wait for the full set of in-sync
      #         replicas to acknowledge the record. This guarantees that the
      #         record will not be lost as long as at least one in-sync replica
      #         remains alive. This is the strongest available guarantee.

      #     If unset, defaults to *acks=1*. If ``enable-idempotence`` is
      #     ``true`` defaults to *acks=all*
      acks: 1

      # compression-type (str): The compression type for all data generated by
      #     the producer. Valid values are 'gzip', 'snappy', 'lz4', or null.
      #     Compression is of full batches of data, so the efficacy of batching
      #     will also impact the compression ratio (more batching means better
      #     compression). Default: null.
      compression-type: null

      # max-batch-size (int): Maximum size of buffered data per partition.
      #     After this amount `send` coroutine will block until batch is
      #     drained.
      #     Default: 16384
      max-batch-size: 16384

      # linger-ms (int): The producer groups together any records that arrive
      #     in between request transmissions into a single batched request.
      #     Normally this occurs only under load when records arrive faster
      #     than they can be sent out. However in some circumstances the client
      #     may want to reduce the number of requests even under moderate load.
      #     This setting accomplishes this by adding a small amount of
      #     artificial delay; that is, if first request is processed faster,
      #     than `linger-ms`, producer will wait `linger-ms - process-time`.
      #     This setting defaults to 0 (i.e. no delay).
      linger-ms: 0

      # max-request-size (int): The maximum size of a request. This is also
      #     effectively a cap on the maximum record size. Note that the server
      #     has its own cap on record size which may be different from this.
      #     This setting will limit the number of record batches the producer
      #     will send in a single request to avoid sending huge requests.
      #     Default: 1048576.
      max-request-size: 1048576

      # metadata-max-age-ms (int): The period of time in milliseconds after
      #     which we force a refresh of metadata even if we haven't seen any
      #     partition leadership changes to proactively discover any new
      #     brokers or partitions. Default: 300000
      metadata-max-age-ms: 300000

      # request-timeout-ms (int): Produce request timeout in milliseconds.
      #     As it's sent as part of ProduceRequest (it's a blocking call),
      #     maximum waiting time can be up to 2 * request-timeout-ms.
      #     Default: 40000.
      request-timeout-ms: 40000

      # retry-backoff-ms (int): Milliseconds to backoff when retrying on
      #     errors. Default: 100.
      retry-backoff-ms: 100

      # api-version (str): specify which kafka API version to use.
      #     If set to 'auto', will attempt to infer the broker version by
      #     probing various APIs. Default: auto
      api-version: auto

      # security-protocol (str): Protocol used to communicate with brokers.
      #     Valid values are: PLAINTEXT, SSL, SASL_PLAINTEXT, SASL_SSL.
      #     Default: PLAINTEXT.
      security-protocol: PLAINTEXT

      # connections-max-idle-ms (int): Close idle connections after the number
      #     of milliseconds specified by this config. Specifying `None` will
      #     disable idle checks. Default: 540000 (9 minutes).
      connection-max-idle-ms: 540000

      # enable-idempotence (bool): When set to ``true``, the producer will
      #     ensure that exactly one copy of each message is written in the
      #     stream. If ``false``, producer retries due to broker failures,
      #     etc., may write duplicates of the retried message in the stream.
      #     Note that enabling idempotence acks to set to 'all'. If it is not
      #     explicitly set by the user it will be chosen. If incompatible
      #     values are set, a ``ValueError`` will be thrown.
      #     New in version 0.5.0.
      enable-idempotence: false

      # sasl-mechanism (str): Authentication mechanism when security-protocol
      #     is configured for SASL_PLAINTEXT or SASL_SSL. Valid values are:
      #     PLAIN, GSSAPI, SCRAM-SHA-256, SCRAM-SHA-512, OAUTHBEARER.
      #     Default: PLAIN
      sasl-mechanism: PLAIN

      # sasl-plain-username (str): username for sasl PLAIN authentication.
      #     Default: None
      sasl-plain-username: null

      # sasl-plain-password (str): password for sasl PLAIN authentication.
      #     Default: None
      sasl-plain-password: null

  inbound:
    group-id: inbound
    topics:
      - acapy-inbound-message

  outbound:
    topic: acapy-outbound-message
    producer:
      # Minimum required config
      # bootstrap-servers: 'host[:port]' string (or list of 'host[:port]'
      #     strings) that the producer should contact to bootstrap initial
      #     cluster metadata. This does not have to be the full node list.
      #     It just needs to have at least one broker that will respond to a
      #     Metadata API Request. Default port is 9092. If no servers are
      #     specified, will default to localhost:9092.
      bootstrap-servers: kafka

      # Extras
      # See producer config above for events; the same config is possible here
